{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05_07: Temperature Anomaly Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import collections\n",
    "import urllib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pp\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getweather\n",
    "\n",
    "def smooth(array, window=10, mode='valid'):\n",
    "    return np.correlate(array, np.ones(window)/window, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['TMIN', 'TMAX'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m station = \u001b[33m'\u001b[39m\u001b[33mNEW YORK\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      5\u001b[39m allyears = np.arange(\u001b[32m1880\u001b[39m, \u001b[32m2020\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m alldata = np.vstack([\u001b[43mgetweather\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetyear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTMIN\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTMAX\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m                      \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m allyears])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Self Study/LinkedIn Learn Exercise/Python/pyProjDataAnalysis_v2.1/chapter5/getweather.py:173\u001b[39m, in \u001b[36mgetyear\u001b[39m\u001b[34m(station_name, elements, year)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgetyear\u001b[39m(station_name, elements, year):\n\u001b[32m    165\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Make a NumPy record array of length 365, containing weather data\u001b[39;00m\n\u001b[32m    166\u001b[39m \u001b[33;03m    at station_name for the list of requested elements (TMIN/TMAX/PRCP/SNOW),\u001b[39;00m\n\u001b[32m    167\u001b[39m \u001b[33;03m    restricted to year.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    170\u001b[39m \u001b[33;03m    with station_name, but give precedence to HCN and GSN stations.\u001b[39;00m\n\u001b[32m    171\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m     alldata = \u001b[43mgetdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstation_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m     \u001b[38;5;66;03m# select data by year, and get rid of the extra day in leap years\u001b[39;00m\n\u001b[32m    176\u001b[39m     \u001b[38;5;66;03m# then pick out the \"element\" column\u001b[39;00m\n\u001b[32m    177\u001b[39m     yeardata = alldata[(alldata.index.year == year) & (alldata.index.dayofyear < \u001b[32m366\u001b[39m)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Self Study/LinkedIn Learn Exercise/Python/pyProjDataAnalysis_v2.1/chapter5/getweather.py:154\u001b[39m, in \u001b[36mgetdata\u001b[39m\u001b[34m(station_name)\u001b[39m\n\u001b[32m    152\u001b[39m pw = pw.pivot(index=\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m, columns=\u001b[33m'\u001b[39m\u001b[33melement\u001b[39m\u001b[33m'\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    153\u001b[39m pw.columns.name = \u001b[38;5;28;01mNone\u001b[39;00m    \n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m pw = \u001b[43mpw\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTMIN\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTMAX\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPRCP\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSNOW\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;66;03m# last, convert temperatures to degrees\u001b[39;00m\n\u001b[32m    157\u001b[39m pw[\u001b[33m'\u001b[39m\u001b[33mTMIN\u001b[39m\u001b[33m'\u001b[39m] /= \u001b[32m10.0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Self Study/LinkedIn Learn Exercise/Python/pyProjDataAnalysis_v2.1/.venv/lib/python3.13/site-packages/pandas/core/frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Self Study/LinkedIn Learn Exercise/Python/pyProjDataAnalysis_v2.1/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Self Study/LinkedIn Learn Exercise/Python/pyProjDataAnalysis_v2.1/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:6252\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6252\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['TMIN', 'TMAX'] not in index\""
     ]
    }
   ],
   "source": [
    "# get all historical data for New York, stacked into array\n",
    "\n",
    "station = 'NEW YORK'\n",
    "\n",
    "allyears = np.arange(1880, 2020)\n",
    "\n",
    "alldata = np.vstack([getweather.getyear(station, ['TMIN','TMAX'], year)\n",
    "                     for year in allyears])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute (TMIN + TMAX)/2, averaged over days in every year\n",
    "allavg = np.nanmean(0.5 * (alldata['TMIN'] + alldata['TMAX']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allavg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allyears.index(1945)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the index of values 1945 and 1955 in allyears\n",
    "list(allyears).index(1945), list(allyears).index(1955)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midcentury = np.nanmean(allavg[65:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midcentury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.plot(allyears, allavg - midcentury)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.plot(allyears[4:-4], smooth(allavg - midcentury, 9, 'valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute and plot the temperature anomaly time series for any station\n",
    "\n",
    "allyears = np.arange(1880, 2020)\n",
    "\n",
    "def plotanomaly(station):\n",
    "    # grab the data\n",
    "    alldata = np.vstack([getweather.getyear(station, ['TMIN','TMAX'], year)\n",
    "                         for year in allyears])\n",
    "    \n",
    "    # make yearly averages, and then the midcentury average\n",
    "    allavg = np.nanmean(0.5 * (alldata[:,:]['TMIN'] + alldata[:,:]['TMAX']), axis=1)\n",
    "    midcentury = np.nanmean(allavg[65:75])\n",
    "    \n",
    "    # plot with smoothing, adding a label that we can show in a legend\n",
    "    pp.plot(allyears[4:-4], smooth(allavg - midcentury, 9, 'valid'), label=station)\n",
    "    \n",
    "    # set a reasonable range\n",
    "    pp.axis(ymin=-3,ymax=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotanomaly('NEW YORK')\n",
    "plotanomaly('PASADENA')\n",
    "plotanomaly('MINNEAPOLIS')\n",
    "\n",
    "pp.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
